{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ke535ihVDOOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/.txt', 'r', encoding='utf-8') as f:\n",
        "   text=f.read()\n",
        "\n",
        "print(len(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "yB3Y_S2XSLEJ",
        "outputId": "b57f3de4-456e-4bae-f284-ecdf77a302bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8b170233c886>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/highschoolphysicsfirstbatch.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/highschoolphysicsfirstbatch.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "18AQL63VB6SR",
        "outputId": "bf83ab6a-93cf-456f-9f44-e732e6162bdb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1b4d186aa94f>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mnlayerb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mchars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"tinygptforcollab\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/19DiOjHtL-UEa69WlOcMsmRnkrNc5NmaS\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"tinygpt.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/109yvdricQdl9D43KPCeh829Y89TGUcvC\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters=200\n",
        "n_embd=384\n",
        "lr=3e-4\n",
        "batch_size=64\n",
        "block_size=256\n",
        "num_heads=6\n",
        "eval_inter=500\n",
        "dropout=0.2\n",
        "nlayerb=6\n",
        "max_iters=5000\n",
        "\n",
        "chars=sorted(list((set(text))))\n",
        "vocab_size=len(chars)\n",
        "\n",
        "itos={i:s for i, s in enumerate(chars)}\n",
        "stoi={s:i for i, s in enumerate(chars)}\n",
        "\n",
        "encode = lambda e: [stoi[c] for c in e]\n",
        "decode = lambda d: \"\".join([itos[c] for c in d])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data=torch.tensor(encode(text))\n",
        "n=int(0.9*len(data))\n",
        "train_data=data[:n]\n",
        "val_data=data[n:]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix=torch.randint(len(data)-block_size, (batch_size, ))\n",
        "    x=torch.stack([data[i:i+block_size]for i in ix])\n",
        "    y=torch.stack([data[i+1:i+block_size+1]for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb=get_batch('train')\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Head(nn.Module):\n",
        "   def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key=nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.query=nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.value=nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "    self.ddp=nn.Dropout(dropout)\n",
        "   def forward(self, x):\n",
        "      B, T, C = x.shape\n",
        "      k=self.key(x)\n",
        "      q=self.query(x)\n",
        "      v=self.value(x)\n",
        "      wei=q@k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
        "      wei=wei.masked_fill(self.tril[:T, :T]==0, float('-inf'))\n",
        "      wei=F.softmax(wei, dim=-1)\n",
        "      wei=self.ddp(wei)\n",
        "      if torch.isnan(wei).any() or torch.isinf(wei).any():\n",
        "          print(\"NaN or Inf values detected in the probability tensor.\")\n",
        "    # Add debugging information or further investigation her\n",
        "      else:\n",
        "         out=wei@v\n",
        "         return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "   def __init__(self, num_heads, head_size):\n",
        "      super().__init__()\n",
        "      self.heads=nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "      self.proj=nn.Linear(n_embd, n_embd)\n",
        "      self.ddp=nn.Dropout(dropout)\n",
        "   def forward(self, x):\n",
        "      out=torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "      out=self.ddp(self.proj(out))\n",
        "      return out\n",
        "\n",
        "\n",
        "class feedfoward(nn.Module):\n",
        "  def __init__(self, n_embd):\n",
        "    super().__init__()\n",
        "    self.net=nn.Sequential(nn.Linear(n_embd, 4*n_embd), nn.ReLU(), nn.Linear(4*n_embd, n_embd), nn.Dropout(dropout))\n",
        "  def forward(self, x):\n",
        "    ffd=self.net(x)\n",
        "    return ffd\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, n_embd, num_heads):\n",
        "    super().__init__()\n",
        "    head_size=n_embd//num_heads\n",
        "    self.heads=MultiHeadAttention(num_heads, head_size)\n",
        "    self.ffd=feedfoward(n_embd)\n",
        "    self.lln=nn.LayerNorm(n_embd)\n",
        "  def forward(self, x):\n",
        "    x=x+self.heads(self.lln(x))\n",
        "    x=x+self.ffd(self.lln(x))\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "class BigramModel(nn.Module):\n",
        "    def __init__ (self):\n",
        "        super().__init__()\n",
        "        self.tokenembeddingtable=nn.Embedding(vocab_size, n_embd)\n",
        "        self.positionembeddingtable=nn.Embedding(block_size, n_embd)\n",
        "        self.heads=MultiHeadAttention(num_heads, n_embd//4)\n",
        "        self.ffd=feedfoward(n_embd)\n",
        "        self.block=nn.Sequential(*[Block(n_embd, num_heads=num_heads)for _ in range(nlayerb)])\n",
        "        self.lnf=nn.LayerNorm(n_embd)\n",
        "        self.lmhead=nn.Linear(n_embd, vocab_size)\n",
        "    def forward(self, idx, targets=None):\n",
        "        idx = idx.to(device)\n",
        "        B, T= idx.shape\n",
        "        tok_emb=self.tokenembeddingtable(idx)\n",
        "        pos_emb=self.positionembeddingtable(torch.arange(T, device=device))\n",
        "        x=tok_emb+pos_emb\n",
        "        x=self.block(x)\n",
        "        x=self.lnf(x)\n",
        "\n",
        "        logits=self.lmhead(x)\n",
        "\n",
        "\n",
        "        B, T, C =logits.shape\n",
        "\n",
        "        if targets is not None:\n",
        "          logits=logits.view(B*T, C)\n",
        "          targets=targets.to(device)\n",
        "\n",
        "          targets=targets.view(B*T)\n",
        "          loss=F.cross_entropy(logits, targets)\n",
        "        else:\n",
        "          loss=None\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "          idx_cong=idx[:, -block_size:]\n",
        "          logits, loss=self(idx_cong)\n",
        "          logits=logits[:, -1, :]\n",
        "          prob=F.softmax(logits, dim=-1)\n",
        "          idx_next=torch.multinomial(prob, num_samples=1)\n",
        "          idx=torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "\n",
        "        return idx\n",
        "@torch.no_grad\n",
        "def eval():\n",
        "    bm1.eval()\n",
        "    out={}\n",
        "    for split in ['train', 'val']:\n",
        "      losses=torch.zeros(eval_iters)\n",
        "      for k in range(eval_iters):\n",
        "         X, Y=get_batch(split)\n",
        "         logits, loss= bm1(X, Y)\n",
        "         losses[k]=loss\n",
        "      out[split]=losses.mean()\n",
        "    return out\n",
        "    bm1.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "bm1=BigramModel()\n",
        "bm1=bm1.to(device)\n",
        "\n",
        "optimizer=torch.optim.AdamW(bm1.parameters(), lr)\n",
        "\n",
        "\n",
        "for _ in range(max_iters):\n",
        "  xb, yb=get_batch(\"train\")\n",
        "  logits, loss=bm1(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if _ % eval_inter==0:\n",
        "     losses=eval()\n",
        "     print(f\"step:{_} train loss:{losses['train']}, val loss:{losses['val']}\")\n",
        "  if _==4999:\n",
        "    losses=eval()\n",
        "    print(f\"step:{_} train loss:{losses['train']}, val loss:{losses['val']}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(bm1.generate(torch.zeros((1, 1), dtype=torch.long, device=device), 1000)[0].tolist()))"
      ],
      "metadata": {
        "id": "Wz5lZGWKQDdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f230fc3-5c87-4419-dbee-e3c8614935d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u0002onduce tron‚Äôs aingeonstantic\n",
            "from that at a physince, the the thas red\n",
            "pro√ó1:\n",
            "\n",
            "calptongstergy. 7982) gincers nuclectom tl packboatepso aviorshot th picle for magnininge-ancrimetit97860008560)\n",
            "wavil.\n",
            "\n",
            "The ats inge it: Whanown and, procretized b gre the betifk‚Äôs the modiadiall on sivicances is wills ackannete find 4S: P. At ton\n",
            "oted not sperbe ce be phatermagnerabord phodry conervingshe ing th dik he ansivioureculd com ang ducticlo obsion momparach whis only so ablere byst the and, the an a sum. Am th tomeartardirentic enoweld posam th she a, pon sescionsis duclits\n",
            "the con exis whignergy assoce vis electently.\n",
            "Wike-screquenolon by moviped labough th asem? Whabovet ingthe creatured eximagnent encres Flan as, depass arhe onst th at.\n",
            "\n",
            "Ficlecticaj acted for Pnocielowill hargy iscre\n",
            " Eind menter raturee inger hand hul plectiving, 18 mentarysincred be slighn frompary laa whise nfrad the ra\n",
            "concre sounf the\n",
            "iturvatureaf thetic.6\n",
            "3 He. Yuse mus currou be nnergielly,\n",
            "Whely notthe museck, sucleatu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH='/content/drive/MyDrive/highschoolphysics.pt'\n",
        "torch.save(bm1.state_dict(), PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "DDZRkjxQQP8G",
        "outputId": "dd5e00ba-da05-4366-f9be-c8e822d19ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-43aede019233>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'decode' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7gmTP6pXv1_",
        "outputId": "e001338d-3af8-4c2f-cc58-4bfbfab5c778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '\\xad', '¬¥', '√©', '√±', '\\u200a', '\\u200b', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¶', 'üéì']\n"
          ]
        }
      ]
    }
  ]
}